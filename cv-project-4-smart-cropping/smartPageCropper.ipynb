{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ9dz52k99Bi"
      },
      "source": [
        "ref: https://stackoverflow.com/questions/61291795/detecting-borders-of-a-page-on-a-table-and-then-refocus"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* pip install numpy\n",
        "* pip install opencv-python\n",
        "* pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g2-0UowP_MAt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "#import PIL\n",
        "#print(PIL.PILLOW_VERSION)\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Whzuy-hUHm_G"
      },
      "outputs": [],
      "source": [
        "input_path = r'D:\\Projects\\repos\\ai\\cv-project-4-smart-cropping\\data'\n",
        "image_filename = '20221205_083430'\n",
        "output_path = r'D:\\Projects\\repos\\ai\\cv-project-4-smart-cropping\\cropped'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Histogram to find threshold values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NT0H5NY-BUr"
      },
      "outputs": [],
      "source": [
        "#Read image and convert to gray.\n",
        "image = cv2.imread(input_path + image_filename +\".jpg\")\n",
        "gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awGEB8AH-JGz"
      },
      "outputs": [],
      "source": [
        "#check histogram to choose threshold values. https://web.archive.org/web/20210224013921/https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.html\n",
        "color = ('b','g','r')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.imshow(image)\n",
        "ax1 = fig.add_subplot(1,2,2)\n",
        "for i,col in enumerate(color):\n",
        "    histogram = cv2.calcHist([image],[i],None,[256],[0,256])\n",
        "    ax1.plot(histogram,color = col)\n",
        "    ax1.set_xlim([0,256])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_zpuglI-VK7"
      },
      "outputs": [],
      "source": [
        "#Use blur to get rid of the notebook's details.\n",
        "blurred_gray_image = cv2.blur(gray_image,(21,21))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24vJ_gC6-eOG"
      },
      "outputs": [],
      "source": [
        "#Do thresholding. Using values which we got from the histogram. https://en.wikipedia.org/wiki/Thresholding_(image_processing)\n",
        "_,thresholded_blurry_image = cv2.threshold(blurred_gray_image,165,255,cv2.THRESH_BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZW8B7Fq-nbg"
      },
      "outputs": [],
      "source": [
        "#Detect contours (which are undivided, closed shapes). https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
        "contours, hierarchy = cv2.findContours(thresholded_blurry_image,\n",
        "cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBtRicnD-vGC"
      },
      "outputs": [],
      "source": [
        "#Draw the biggest contour's outline to the copy of the original image if there are any contours.Source post for finding the biggest contour.\n",
        "output = image.copy()\n",
        "if len(contours) != 0:\n",
        "    c = max(contours, key = cv2.contourArea)\n",
        "    # coordinates of the contour\n",
        "    x,y,w,h = cv2.boundingRect(c)\n",
        "    cv2.rectangle(output,(x,y),(x+w,y+h),(0,0,255),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t6KhBIw-z21"
      },
      "outputs": [],
      "source": [
        "#Show the result\n",
        "output = cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBZGi1euEg9F"
      },
      "outputs": [],
      "source": [
        "#now crop image\n",
        "output = output[y:y+h, x:x+w]\n",
        "plt.imshow(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa48q-vzFM7r"
      },
      "outputs": [],
      "source": [
        "# save cropped image\n",
        "status = cv2.imwrite(output_path + image_filename + '_cropped' + '.jpg', output)\n",
        " \n",
        "print(\"Image written to file-system : \",status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYUEyriX_Bit"
      },
      "source": [
        "Use cv2.imwrite() function to save the image.\n",
        "\n",
        "Be aware that this method won't always work because we evaluate the histogram ourselves and pick the thresholding values by hand. If you want to take a more general approach try adaptive thresholding or evaluate histogram values with help of an algorithm."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bulk Smart Page Cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f94UGLeEHZ_R"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iihGmtdZHh7n"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_images \u001b[39m=\u001b[39m load_images_from_folder(input_path)\n",
            "Cell \u001b[1;32mIn[20], line 4\u001b[0m, in \u001b[0;36mload_images_from_folder\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m      2\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(folder):\n\u001b[1;32m----> 4\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(folder,filename))\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m img \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         images\u001b[39m.\u001b[39mappend(img)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "raw_images = load_images_from_folder(input_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yMQXjRlLH9K2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "677\n"
          ]
        }
      ],
      "source": [
        "print(len(raw_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cropImage(images):\n",
        "    for image in images:\n",
        "        #Read image and convert to gray.\n",
        "        gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        #Use blur to get rid of the notebook's details.\n",
        "        blurred_gray_image = cv2.blur(gray_image,(21,21))\n",
        "        #forget histogram, we assume threshold values from testing earlier\n",
        "        _,thresholded_blurry_image = cv2.threshold(blurred_gray_image,165,255,cv2.THRESH_BINARY)\n",
        "        #Detect contours (which are undivided, closed shapes).\n",
        "        contours, hierarchy = cv2.findContours(thresholded_blurry_image,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        output = image.copy()\n",
        "        if len(contours) != 0:\n",
        "            c = max(contours, key = cv2.contourArea)\n",
        "            # coordinates of the contour\n",
        "            x,y,w,h = cv2.boundingRect(c)\n",
        "        #now crop image\n",
        "        output = image[y:y+h, x:x+w]\n",
        "        # save cropped image\n",
        "        status = cv2.imwrite(output_path + image_filename + '_cropped' + '.jpg', output)\n",
        "        print(image_filename + \" written to \" + output_path + \": \" + status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cropImage(raw_images)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_cv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "d88a793758dbf27148ae057ed02bb8117fca282e6413a76e24712a37f85d2994"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
